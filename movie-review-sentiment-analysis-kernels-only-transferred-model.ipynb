{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;36mfastai\u001b[0m@                                             test.tsv\r\n",
      "\u001b[01;34mlabeled_text\u001b[0m/                                       TEXT.pkl\r\n",
      "\u001b[01;34mmodels\u001b[0m/                                             \u001b[01;34mtmp\u001b[0m/\r\n",
      "movie-review-sentiment-analysis-kernels-only.ipynb  train.tsv\r\n",
      "sampleSubmission.csv                                Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "#Make\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"test.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop incomplete sentences in training set\n",
    "def dropIncomplete (df, label=\"SentenceId\", keepLocation=0):\n",
    "    sentences = []\n",
    "    for i in df[label].unique():  \n",
    "        sentences.append(df[df[label] == i].reset_index(drop=True).loc[keepLocation])\n",
    "    df_result = pd.DataFrame(sentences)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dropIncomplete(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dropIncomplete(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(df_train[\"Phrase\"]).reset_index(drop=True)\n",
    "df_test = pd.DataFrame(df_test[\"Phrase\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase\n",
       "0  A series of escapades demonstrating the adage ...\n",
       "1  This quiet , introspective and entertaining in...\n",
       "2  Even fans of Ismail Merchant 's work , I suspe...\n",
       "3  A positively thrilling combination of ethnogra...\n",
       "4  Aggressive self-glorification and a manipulati..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I kept wishing I was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase\n",
       "0  An intermittently pleasing but mostly routine ...\n",
       "1  Kidman is really the only thing that 's worth ...\n",
       "2  Once you get into its rhythm ... the movie bec...\n",
       "3  I kept wishing I was watching a documentary ab...\n",
       "4  Kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test imdb language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing to load model\n",
    "spacy_tok = spacy.load('en')\n",
    "TEXT = pickle.load(open(\"TEXT_imdb.pkl\",\"rb\")) #TEXT field from imdb data set\n",
    "bs=64; bptt=70\n",
    "md = LanguageModelData.from_dataframes(path=\"labeled_text\",field=TEXT,col=\"Phrase\",train_df=df_train, val_df=df_test,\n",
    "                                       test_df=df_test,bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200\n",
    "nh = 500\n",
    "nl = 3\n",
    "opt_fn = partial(optim.Adam, betas = (0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl, dropouti=0.05, dropout=0.05,\n",
    "                       wdrop=0.1, dropoute=0.02, dropouth=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pretrained enconder from imdb dataset\n",
    "learner.load_encoder('adam3_imdb_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is not something that i will have watched'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use our torchtext field to numericalize it so we can feed it to our language model.\n",
    "m = learner.model\n",
    "ss = \"\"\"This is not something that I will have watched\"\"\"\n",
    "s = [TEXT.preprocess(ss)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps to test a language model\n",
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['before', 'over', '.', 'in', 'again', 'for', 'on', ',', 'since', 'at']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 predictions\n",
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not something that I will have watched \n",
      "\n",
      "before the end of the film . the film is a bit of a mess , but it 's a ...\n"
     ]
    }
   ],
   "source": [
    "#generate a bit more text\n",
    "print(ss,\"\\n\")\n",
    "for i in range(20):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res, *_ =m(n[0].unsqueeze(0))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  Sentiment\n",
       "0  A series of escapades demonstrating the adage ...          1\n",
       "1  This quiet , introspective and entertaining in...          4\n",
       "2  Even fans of Ismail Merchant 's work , I suspe...          1\n",
       "3  A positively thrilling combination of ethnogra...          3\n",
       "4  Aggressive self-glorification and a manipulati...          1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process training set data with sentiment label\n",
    "df_trainWLabels = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "df_trainWLabels = dropIncomplete(df_trainWLabels)\n",
    "df_trainWLabels.drop([\"PhraseId\", \"SentenceId\"], axis = 1,inplace=True)\n",
    "df_trainWLabels.reset_index(inplace=True, drop=True)\n",
    "df_trainWLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_trainWLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"labeled_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntoLabeledFolders(df, folderPath, validRatio=0.3, contentIndex=0, labelIndex=1):\n",
    "    count = 1\n",
    "    L = len(df)\n",
    "    cutPoint = int(round((1-validRatio)*L))\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        phrase=row[contentIndex]\n",
    "        label = row[labelIndex]\n",
    "        if (count<cutPoint):\n",
    "            filename = os.path.join(folderPath,\"train\", str(label), str(count))+\".txt\"\n",
    "        else:\n",
    "            filename = os.path.join(folderPath,\"valid\", str(label), str(count))+\".txt\"\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        with open(filename,\"w\") as f:\n",
    "            f.write(phrase)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntoLabeledFolders(df=df_trainWLabels, folderPath = folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show labels ###Start here if already created labeled folders\n",
    "labelList = !ls labeled_text/train\n",
    "labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[755, 1550, 1153, 1620, 891]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count number of samples under each label\n",
    "labelCount = []\n",
    "for i in labelList:\n",
    "    trn_files = !ls labeled_text/train/{i}\n",
    "    labelCount.append(len(trn_files))\n",
    "labelCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It throws quirky characters , odd situations , and off-kilter dialogue at us , all as if to say , `` Look at this !']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review sentences\n",
    "label = 3\n",
    "fileIndex = 40\n",
    "FileList = !ls labeled_text/train/{label}\n",
    "sample = !cat labeled_text/train/{label}/{FileList[fileIndex]}\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create torch text object\n",
    "class MovieReview(torchtext.data.Dataset):\n",
    "    \"\"\"Create a MovieReview dataset instance given a path and fields.\n",
    "    Arguments:\n",
    "        path: Path to the dataset's highest level directory\n",
    "        text_field: The field that will be used for text data.\n",
    "        label_field: The field that will be used for label data.\n",
    "        Remaining keyword arguments: Passed to the constructor of\n",
    "            data.Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, text_field, label_field, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        examples = []\n",
    "        for label in ['0','1','2','3','4']:\n",
    "            fnames = glob.glob(os.path.join(path, label, \"*.txt\"))\n",
    "            assert fnames, f\"can't find file under {path}/{label}\"\n",
    "            for fname in fnames:\n",
    "                with open(fname, \"r\") as f: text = f.readline()\n",
    "                examples.append(data.Example.fromlist([text,label], fields))\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sort_key(ex): return len(ex.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, root='.data', \n",
    "               train='train', test='test', **kwargs):\n",
    "        return super().splits(\n",
    "            root, text_field=text_field, label_field=label_field,\n",
    "            train=train, validation=None, test=test, **kwargs)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "MovieReviewLabel = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(\"TEXT_imdb.pkl\",\"rb\")) #open in read and bineary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"labeled_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = MovieReview.splits(TEXT, MovieReviewLabel, PATH,train=\"train\", test=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = splits[0].examples[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0',\n",
       " \"godard 's ode to tackling life 's wonderment is a rambling and incoherent manifesto about the vagueness of topical excess ... in praise of love remains a ponderous and pretentious\")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.label, \" \".join(t.text[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64; bptt = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;36mfastai\u001b[0m@\r\n",
      "\u001b[01;34mlabeled_text\u001b[0m/\r\n",
      "\u001b[01;34mmodels\u001b[0m/\r\n",
      "movie-review-sentiment-analysis-kernels-only.ipynb\r\n",
      "movie-review-sentiment-analysis-kernels-only-transferred-model.ipynb\r\n",
      "sampleSubmission.csv\r\n",
      "test.tsv\r\n",
      "TEXT_imdb.pkl\r\n",
      "TEXT.pkl\r\n",
      "\u001b[01;34mtmp\u001b[0m/\r\n",
      "train.tsv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.load_encoder('adam3_imdb_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.clip=25.\n",
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55c7338c3af4f0c95b07411557a94fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.47961    1.324243   0.426232  \n",
      "    1      1.387777   1.273014   0.448345                 \n",
      "    2      1.381538   1.287076   0.429342                 \n",
      "    3      1.339347   1.249393   0.448537                 \n",
      "    4      1.355395   1.232047   0.455236                 \n",
      "    5      1.314312   1.228462   0.458077                 \n",
      "    6      1.336506   1.226022   0.457905                 \n",
      "    7      1.303152   1.228552   0.458711                 \n",
      "    8      1.320887   1.236427   0.448844                 \n",
      "    9      1.288927   1.231241   0.449497                 \n",
      "    10     1.290093   1.24058    0.449958                 \n",
      "    11     1.27969    1.215563   0.461302                 \n",
      "    12     1.287484   1.255894   0.443643                 \n",
      "    13     1.272589   1.225182   0.455505                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.22518]), 0.4555052211302211]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 7, metrics=[accuracy], cycle_len=2, cycle_save_name='MovieREview')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
